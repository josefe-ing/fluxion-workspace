# ğŸ“‹ Instrucciones para ValidaciÃ³n de Datos ETL

## Contexto

DespuÃ©s de las optimizaciones del ETL (remociÃ³n de lÃ­mites, cambio a SQLAlchemy, eliminaciÃ³n de OFFSET/FETCH), necesitamos validar que los datos sincronizados sean correctos y completos.

Existen **2 scripts de validaciÃ³n** disponibles:

---

## 1ï¸âƒ£ ValidaciÃ³n Local (Sin VPN)

**Script:** `etl/core/validar_datos_local.py`

**PropÃ³sito:** Analiza Ãºnicamente los datos ya sincronizados en DuckDB para detectar:
- DÃ­as sin datos (gaps)
- AnomalÃ­as estadÃ­sticas (dÃ­as con muy pocos o muchos registros comparados con el promedio)
- Resumen de ventas por dÃ­a

**Ventajas:**
- âœ… NO requiere conexiÃ³n a SQL Server
- âœ… NO requiere VPN
- âœ… RÃ¡pido (solo consulta DuckDB local)

**Desventajas:**
- âš ï¸ No compara contra la fuente de verdad (SQL Server)
- âš ï¸ Solo detecta patrones sospechosos, no errores confirmados

### Uso:

```bash
cd /Users/jose/Developer/fluxion-workspace/etl/core

# Validar tienda 01 para octubre 1-22, 2025
python3 validar_datos_local.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22

# Con exportaciÃ³n a CSV
python3 validar_datos_local.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22 \
  --export-csv /tmp/validacion_tienda01_local.csv
```

### Salida:

```
================================================================================
ğŸ” VALIDACIÃ“N LOCAL DE DATOS: PERIFERICO
================================================================================
ğŸ“… PerÃ­odo: 2025-10-01 a 2025-10-22
ğŸ’¾ DuckDB: /Users/jose/Developer/fluxion-workspace/data/fluxion_production.db
================================================================================

ğŸ“Š Consultando datos sincronizados...
   âœ… Encontrados datos para 21 dÃ­as

====================================================================================================
ğŸ“Š REPORTE DE VALIDACIÃ“N LOCAL - PERIFERICO
====================================================================================================

ğŸ“ˆ RESUMEN GENERAL:
   Total dÃ­as analizados: 22
   âœ… DÃ­as con datos: 21 (95.5%)
   âŒ DÃ­as sin datos: 1
   âš ï¸  DÃ­as con anomalÃ­as: 2
   âœ… DÃ­as normales: 19

   ğŸ“Š Total registros: 567,234
   ğŸ§¾ Total facturas: 12,456
   ğŸ’° Venta total: $234,567.89

   ğŸ“Š Promedio diario: 27,011 registros
   ğŸ“Š Mediana diaria: 26,543 registros
   ğŸ“Š DesviaciÃ³n estÃ¡ndar: 3,421 registros

====================================================================================================
ğŸ“… DETALLE POR DÃA:
====================================================================================================
Fecha        Registros    Facturas     Venta Total    Venta Prom     Estado          Observaciones
----------------------------------------------------------------------------------------------------------------------------
2025-10-01      28,123      1,234       $12,345.67     $10.02         âœ… NORMAL       Dentro del rango esperado
2025-10-02      26,543      1,187       $11,234.56     $9.88          âœ… NORMAL       Dentro del rango esperado
2025-10-03           0          0            $0.00     $0.00          âŒ SIN DATOS    No hay registros para este dÃ­a
...
```

---

## 2ï¸âƒ£ ValidaciÃ³n Completa con SQL Server (Con VPN)

**Script:** `etl/core/validar_calidad_datos.py`

**PropÃ³sito:** Compara dÃ­a por dÃ­a los conteos entre:
- **SQL Server** (fuente de verdad)
- **DuckDB** (datos sincronizados)

**Ventajas:**
- âœ… ValidaciÃ³n exacta contra la fuente de verdad
- âœ… Detecta discrepancias precisas (faltantes o excesos)
- âœ… Genera recomendaciones de re-sincronizaciÃ³n especÃ­ficas

**Desventajas:**
- âš ï¸ Requiere conexiÃ³n VPN a SQL Server
- âš ï¸ MÃ¡s lento (consulta ambas bases de datos)

### Uso:

```bash
# IMPORTANTE: Conectarse a la VPN PRIMERO
cd /Users/jose/Developer/fluxion-workspace/etl/core

# Validar tienda 01 para octubre 1-22, 2025
python3 validar_calidad_datos.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22

# Con exportaciÃ³n a CSV
python3 validar_calidad_datos.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22 \
  --export-csv /tmp/validacion_tienda01_completa.csv
```

### Salida:

```
================================================================================
ğŸ” VALIDANDO CALIDAD DE DATOS: PERIFERICO
================================================================================
ğŸ“… PerÃ­odo: 2025-10-01 a 2025-10-22
ğŸ“¡ SQL Server: 192.168.20.12:14348
ğŸ’¾ DuckDB: /Users/jose/Developer/fluxion-workspace/data/fluxion_production.db
================================================================================

ğŸ“Š Consultando SQL Server (fuente de verdad)...
   âœ… SQL Server: 21 dÃ­as con datos
ğŸ’¾ Consultando DuckDB (datos sincronizados)...
   âœ… DuckDB: 19 dÃ­as con datos

ğŸ” Comparando datos dÃ­a por dÃ­a...

====================================================================================================
ğŸ“Š REPORTE DE VALIDACIÃ“N DE CALIDAD - PERIFERICO
====================================================================================================

ğŸ“ˆ RESUMEN GENERAL:
   Total dÃ­as analizados: 22
   âœ… DÃ­as con match perfecto: 19 (86.4%)
   âš ï¸  DÃ­as sin datos (ambas fuentes): 0
   âŒ DÃ­as con registros faltantes: 2
   âš ï¸  DÃ­as con registros de mÃ¡s: 0

   ğŸ“Š Total registros en SQL Server: 567,890
   ğŸ’¾ Total registros en DuckDB: 510,234
   ğŸ“‰ Diferencia: -57,656
   ğŸ“Š Porcentaje de completitud: 89.85%

====================================================================================================
ğŸ“… DETALLE POR DÃA:
====================================================================================================
Fecha        SQL Server      DuckDB    Diferencia    Match %     Estado
----------------------------------------------------------------------------------------------------
2025-10-01       28,123      28,123            +0     100.0%     âœ… PERFECTO
2025-10-02       26,543      26,543            +0     100.0%     âœ… PERFECTO
2025-10-03       27,456           0       -27,456       0.0%     âŒ FALTANTE
2025-10-04       29,834      29,834            +0     100.0%     âœ… PERFECTO
...

====================================================================================================
âš ï¸  DÃAS CON DISCREPANCIAS:
====================================================================================================
   âŒ FALTANTE 2025-10-03: SQL=27,456, DuckDB=0, Dif=-27,456
   âŒ FALTANTE 2025-10-15: SQL=30,200, DuckDB=0, Dif=-30,200

====================================================================================================

ğŸ’¡ RECOMENDACIONES:
   â€¢ Re-ejecutar ETL para el perÃ­odo: 2025-10-03 a 2025-10-15
   â€¢ Comando sugerido:
     python3 etl_ventas.py --tienda tienda_01 --fecha-inicio 2025-10-03 --fecha-fin 2025-10-15
```

---

## ğŸ¯ Flujo de Trabajo Recomendado

### Paso 1: ValidaciÃ³n RÃ¡pida (Sin VPN)
```bash
# Ejecutar validaciÃ³n local para detectar patrones sospechosos
python3 validar_datos_local.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22
```

Si detectas dÃ­as sin datos o anomalÃ­as, procede al Paso 2.

### Paso 2: ValidaciÃ³n Completa (Con VPN)
```bash
# Conectar VPN primero
# Luego ejecutar validaciÃ³n completa contra SQL Server
python3 validar_calidad_datos.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22 \
  --export-csv /tmp/validacion_completa.csv
```

### Paso 3: Re-sincronizaciÃ³n de Gaps (Con VPN)
```bash
# Si la validaciÃ³n detectÃ³ gaps, re-ejecutar ETL para esos dÃ­as
cd /Users/jose/Developer/fluxion-workspace/etl/core

python3 etl_ventas.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-03 \
  --fecha-fin 2025-10-03  # DÃ­a especÃ­fico
```

### Paso 4: Re-validaciÃ³n
```bash
# Volver a ejecutar validaciÃ³n completa para confirmar
python3 validar_calidad_datos.py \
  --tienda tienda_01 \
  --fecha-inicio 2025-10-01 \
  --fecha-fin 2025-10-22
```

---

## ğŸ“ Notas Importantes

### Sobre los Scripts

1. **Ambos scripts** usan el mismo SQL query que el ETL para contar registros en SQL Server, garantizando consistencia.

2. **ubicacion_id vs tienda_id**: Los scripts usan `ubicacion_id` internamente (de la configuraciÃ³n) pero el parÃ¡metro CLI es `--tienda tienda_01` por claridad.

3. **CÃ³digos de salida**:
   - `0` = ValidaciÃ³n exitosa, sin problemas
   - `1` = Se encontraron discrepancias o errores

### Tiendas Disponibles

Para ver todas las tiendas configuradas:
```bash
cd /Users/jose/Developer/fluxion-workspace/etl/core
python3 etl_ventas.py --mostrar-tiendas
```

Ejemplo de salida:
```
ğŸª TIENDAS DISPONIBLES:
==================================================
   tienda_01: PERIFERICO
   tienda_08: PRINCIPAL
   tienda_10: CATIA
   ...
==================================================
```

### Validar MÃºltiples Tiendas

Para validar todas las tiendas activas, puedes crear un simple loop:

```bash
# ValidaciÃ³n local (sin VPN)
for tienda in tienda_01 tienda_08 tienda_10; do
  echo "Validando $tienda..."
  python3 validar_datos_local.py \
    --tienda $tienda \
    --fecha-inicio 2025-10-01 \
    --fecha-fin 2025-10-22
done

# ValidaciÃ³n completa (con VPN)
for tienda in tienda_01 tienda_08 tienda_10; do
  echo "Validando $tienda contra SQL Server..."
  python3 validar_calidad_datos.py \
    --tienda $tienda \
    --fecha-inicio 2025-10-01 \
    --fecha-fin 2025-10-22 \
    --export-csv /tmp/validacion_${tienda}.csv
done
```

---

## ğŸ”§ Troubleshooting

### Error: "Login timeout expired"
- **Causa**: No estÃ¡s conectado a la VPN
- **SoluciÃ³n**: Conectar VPN y reintentar
- **Script afectado**: Solo `validar_calidad_datos.py` (el que consulta SQL Server)

### Error: "ubicacion_id = ?" returned no results
- **Causa**: La tienda no tiene datos para ese rango de fechas
- **SoluciÃ³n**: Verificar que el rango de fechas sea correcto y que la tienda tenga ventas en ese perÃ­odo

### Error: "No function matches 'sum(VARCHAR)'"
- **Causa**: La tabla `ventas_raw` almacena nÃºmeros como texto
- **SoluciÃ³n**: âœ… Ya corregido en ambos scripts usando `TRY_CAST()`

### Performance lento en validaciÃ³n completa
- **Causa**: Consultar SQL Server para muchos dÃ­as puede ser lento
- **SoluciÃ³n**: Validar en rangos mÃ¡s pequeÃ±os (7-14 dÃ­as a la vez)

---

## ğŸ“Š PrÃ³ximos Pasos

DespuÃ©s de validar los datos sincronizados:

1. âœ… Ejecutar validaciÃ³n local para identificar gaps rÃ¡pidamente
2. âœ… Ejecutar validaciÃ³n completa (con VPN) para confirmar discrepancias exactas
3. âœ… Re-sincronizar dÃ­as faltantes especÃ­ficos
4. âœ… Compartir `GUIA_DBA_TCP_KEEPALIVE.md` con DBA para mejorar estabilidad de conexiones
5. âœ… Configurar ETL programado en AWS con los scripts optimizados

---

**Ãšltima actualizaciÃ³n:** 2025-10-22
**Scripts creados por:** Claude Code Optimization Session
