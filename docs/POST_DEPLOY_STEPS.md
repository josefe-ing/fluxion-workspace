# Post-Deploy Steps - Sistema KLK v2.0

**Deploy Status**: ‚úÖ EXITOSO
**Fecha**: 2025-11-24 15:10
**Workflow**: https://github.com/josefe-ing/fluxion-workspace/actions/runs/19645390484

---

## ‚úÖ Deploy Completado

Todos los jobs del workflow completaron exitosamente:
- ‚úÖ Backend Build & Test
- ‚úÖ Frontend Build & Test
- ‚úÖ Build & Push Backend Docker Image
- ‚úÖ Deploy Infrastructure & Backend
- ‚úÖ Deploy Frontend
- ‚úÖ Health Check

**URLs de Producci√≥n**:
- Frontend: https://d20a0g9yxinot2.cloudfront.net
- Backend: https://d1tgnaj74tv17v.cloudfront.net

---

## ‚ö†Ô∏è  Paso Cr√≠tico Pendiente

### El c√≥digo est√° desplegado PERO falta crear la tabla en DB de producci√≥n

**Error actual**:
```
Catalog Error: Table with name etl_ejecuciones does not exist!
```

**Causa**: El schema SQL `database/schema_etl_tracking.sql` NO se ejecut√≥ autom√°ticamente en la base de datos de producci√≥n.

---

## üîß Soluci√≥n: Ejecutar Schema SQL

### Opci√≥n 1: Via ECS Task (Recomendado)

1. **Conectarse al backend container via SSM**:
```bash
# 1. Obtener task ID
TASK_ID=$(aws ecs list-tasks --cluster fluxion-cluster \
  --service-name FluxionStackV2-FluxionBackendServiceE051E4B7-3D0YfNUbXnmp \
  --query 'taskArns[0]' --output text | cut -d'/' -f3)

echo "Task ID: $TASK_ID"

# 2. Conectarse al container
aws ecs execute-command \
  --cluster fluxion-cluster \
  --task $TASK_ID \
  --container fluxion-backend \
  --interactive \
  --command "/bin/bash"
```

2. **Dentro del container, ejecutar el schema**:
```bash
# Verificar que el schema existe
ls -la /app/database/schema_etl_tracking.sql

# Ejecutar schema con Python
python3 << 'EOF'
import duckdb
from pathlib import Path

# Path a la DB en EFS
db_path = "/mnt/efs/data/fluxion_production.db"
schema_path = "/app/database/schema_etl_tracking.sql"

# Leer schema
with open(schema_path, 'r') as f:
    schema_sql = f.read()

# Conectar y ejecutar
conn = duckdb.connect(db_path)

# Ejecutar cada statement
for statement in schema_sql.split(';'):
    statement = statement.strip()
    if statement:
        print(f"Ejecutando: {statement[:60]}...")
        try:
            conn.execute(statement)
            print("  ‚úÖ OK")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Error: {e}")

conn.close()
print("\n‚úÖ Schema aplicado exitosamente!")
EOF

# Verificar que la tabla existe
python3 << 'EOF'
import duckdb
conn = duckdb.connect("/mnt/efs/data/fluxion_production.db")
result = conn.execute("SELECT COUNT(*) as count FROM etl_ejecuciones").fetchone()
print(f"‚úÖ Tabla etl_ejecuciones creada - {result[0]} registros")
conn.close()
EOF
```

3. **Salir del container**:
```bash
exit
```

### Opci√≥n 2: Via Script de Migraci√≥n

Crear un script de migraci√≥n y ejecutarlo como ECS task one-off:

```bash
# 1. Crear script de migraci√≥n
cat > /tmp/apply_etl_tracking_schema.py << 'EOF'
#!/usr/bin/env python3
import duckdb
from pathlib import Path

db_path = Path("/mnt/efs/data/fluxion_production.db")
schema_path = Path("/app/database/schema_etl_tracking.sql")

print(f"üîç Verificando DB: {db_path}")
print(f"üîç Schema file: {schema_path}")

with open(schema_path, 'r') as f:
    schema_sql = f.read()

conn = duckdb.connect(str(db_path))

statements = [s.strip() for s in schema_sql.split(';') if s.strip()]
print(f"\nüìù Ejecutando {len(statements)} statements...")

for i, statement in enumerate(statements, 1):
    try:
        conn.execute(statement)
        print(f"  [{i}/{len(statements)}] ‚úÖ OK")
    except Exception as e:
        print(f"  [{i}/{len(statements)}] ‚ö†Ô∏è  {str(e)[:100]}")

conn.close()
print("\n‚úÖ Migraci√≥n completada!")
EOF

# 2. Copiar al container y ejecutar
# (requiere acceso al container via ECS exec)
```

### Opci√≥n 3: Via WireGuard Bridge + DuckDB CLI

Si tienes acceso directo a la DB via WireGuard:

```bash
# 1. Conectarse a la instancia WireGuard
aws ssm start-session --target i-07cc62e4314a4a67a

# 2. Desde la instancia, acceder a EFS
sudo su
cd /mnt/efs/data

# 3. Aplicar schema
duckdb fluxion_production.db < /path/to/schema_etl_tracking.sql

# 4. Verificar
duckdb fluxion_production.db "SELECT COUNT(*) FROM etl_ejecuciones"
```

---

## üß™ Validaci√≥n Post-Schema

Despu√©s de aplicar el schema, verificar:

### 1. Endpoint de Ejecuciones
```bash
curl 'https://d1tgnaj74tv17v.cloudfront.net/api/etl/tracking/ejecuciones?limite=5'
# Deber√≠a retornar: [] (array vac√≠o, no error)
```

### 2. Endpoint de Cron Status
```bash
curl 'https://d1tgnaj74tv17v.cloudfront.net/api/etl/tracking/cron/status' | jq
# Deber√≠a retornar JSON con m√©tricas (ejecuciones_hoy: 0)
```

### 3. Endpoint de Gaps
```bash
curl 'https://d1tgnaj74tv17v.cloudfront.net/api/etl/tracking/gaps' | jq
# Deber√≠a retornar: [] (array vac√≠o)
```

### 4. Frontend - Panel de Tracking
```bash
open https://d20a0g9yxinot2.cloudfront.net
# Navegar a: Configuraci√≥n ‚Üí KLK Tracking
# Deber√≠a mostrar: "No hay ejecuciones registradas" (sin errores HTTP 500)
```

---

## üìä Estado Actual del Sistema

### C√≥digo Desplegado
- ‚úÖ Backend: Nuevo c√≥digo con etl_tracking_router
- ‚úÖ Frontend: Componentes de tracking UI
- ‚úÖ Docker Images: Pusheadas a ECR
- ‚úÖ CloudFront: Invalidado y actualizado

### Base de Datos
- ‚ö†Ô∏è  Tabla `etl_ejecuciones`: **NO EXISTE A√öN**
- ‚ö†Ô∏è  Vistas SQL: **NO EXISTEN A√öN**
- ‚ö†Ô∏è  Secuencias: **NO EXISTEN A√öN**

### Funcionalidad
- ‚úÖ Backend health check: Funcionando
- ‚úÖ Endpoints existentes: Funcionando
- ‚ö†Ô∏è  Endpoints `/api/etl/tracking/*`: **ERROR 500** (tabla faltante)
- ‚ö†Ô∏è  Frontend tracking panels: **ERROR** (API falla)

---

## üö® Errores Pre-Existentes (NO Causados por Deploy)

Los siguientes errores ya exist√≠an ANTES del deploy:

1. **`almacen_codigo` column not found** (ubicaciones/summary)
2. **`fecha_pedido` column not found** (pedidos-sugeridos)

Estos NO son relacionados con el deploy de hoy y pueden ser ignorados por ahora.

---

## üéØ Pr√≥ximos Pasos (Orden)

1. **[CR√çTICO]** Ejecutar schema SQL en producci√≥n (usar Opci√≥n 1)
2. **[VALIDAR]** Probar endpoints de tracking
3. **[VALIDAR]** Abrir frontend y verificar panels de tracking
4. **[OPCIONAL]** Configurar Sentry DSN en variables de entorno ECS
5. **[OPCIONAL]** Ejecutar primer ETL manual para poblar tabla
6. **[OPCIONAL]** Configurar alertas en Sentry

---

## üìû Comando R√°pido para Aplicar Schema

```bash
# Todo en uno - Ejecutar schema via ECS exec
TASK_ID=$(aws ecs list-tasks --cluster fluxion-cluster \
  --service-name FluxionStackV2-FluxionBackendServiceE051E4B7-3D0YfNUbXnmp \
  --query 'taskArns[0]' --output text | cut -d'/' -f3)

aws ecs execute-command \
  --cluster fluxion-cluster \
  --task $TASK_ID \
  --container fluxion-backend \
  --interactive \
  --command "/bin/bash"

# Luego dentro del container:
# python3 -c "import duckdb; conn = duckdb.connect('/mnt/efs/data/fluxion_production.db'); conn.execute(open('/app/database/schema_etl_tracking.sql').read()); print('‚úÖ Schema aplicado!')"
```

---

**Estado**: ‚è∏Ô∏è  Deploy exitoso, esperando aplicaci√≥n de schema SQL
**Pr√≥ximo paso**: Ejecutar schema en producci√≥n para activar funcionalidad de tracking
